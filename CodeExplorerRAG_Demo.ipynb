{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for our RAG application and teaching agent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "import glob\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "import time  # For timing stages\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Setup Environment and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setup Environment and LLM\n",
    "# This is like setting up your classroom with the right tools\n",
    "def setup_environment():\n",
    "    load_dotenv()\n",
    "    if not os.getenv(\"GROQ_API_KEY\"):\n",
    "        raise ValueError(\"Please set GROQ_API_KEY in your .env file!\")\n",
    "    llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "    print(\"Environment setup complete. Your AI teacher is ready!\")\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Documents from Any Code Folder\n",
    "# Simplified version with optimized chunk size\n",
    "import os\n",
    "import glob\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import re\n",
    "\n",
    "def generate_tree_structure(directory):\n",
    "    \"\"\"Generate a textual representation of the directory tree.\"\"\"\n",
    "    tree = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        level = root.replace(directory, '').count(os.sep)\n",
    "        indent = '  ' * level\n",
    "        tree.append(f\"{indent}{os.path.basename(root)}/\")\n",
    "        for f in files:\n",
    "            tree.append(f\"{indent}  {f}\")\n",
    "    return \"\\n\".join(tree)\n",
    "\n",
    "def infer_code_flow(files, directory):\n",
    "    \"\"\"Basic inference of code flow by looking at imports/requires.\"\"\"\n",
    "    flow = []\n",
    "    import_patterns = {\n",
    "        'py': r\"import\\s+[\\w.]+\\s*(?:as\\s+\\w+)?|from\\s+[\\w.]+\\s+import\\s+[\\w.*]+\",\n",
    "        'js': r\"import\\s+.*?\\s+from\\s+['\\\"].*?['\\\"]|require\\(['\\\"].*?['\\\"]\\)\",\n",
    "        'jsx': r\"import\\s+.*?\\s+from\\s+['\\\"].*?['\\\"]|require\\(['\\\"].*?['\\\"]\\)\"\n",
    "    }\n",
    "    \n",
    "    for file_path in files:\n",
    "        ext = file_path.rsplit('.', 1)[-1] if '.' in file_path else ''\n",
    "        if ext in import_patterns:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                imports = re.findall(import_patterns[ext], content)\n",
    "                if imports:\n",
    "                    rel_path = os.path.relpath(file_path, directory)\n",
    "                    flow.append(f\"{rel_path} depends on:\")\n",
    "                    for imp in imports:\n",
    "                        flow.append(f\"  - {imp.strip()}\")\n",
    "            except Exception as e:\n",
    "                flow.append(f\"Error analyzing {file_path}: {e}\")\n",
    "    return \"\\n\".join(flow) if flow else \"No detectable dependencies found.\"\n",
    "\n",
    "def load_documents(directory=\"code_folder\"):\n",
    "    \"\"\"Load code files, tree, and flow from the directory.\"\"\"\n",
    "    # Verify directory exists\n",
    "    abs_dir = os.path.abspath(directory)\n",
    "    if not os.path.isdir(abs_dir):\n",
    "        print(f\"Error: Directory '{abs_dir}' does not exist!\")\n",
    "        return []\n",
    "    print(f\"Scanning directory: {abs_dir}\")\n",
    "\n",
    "    # Define supported extensions\n",
    "    extensions = (\"py\", \"js\", \"jsx\", \"ts\", \"java\", \"c\", \"cpp\", \"cs\", \"go\", \"rs\", \n",
    "                  \"php\", \"rb\", \"sh\", \"txt\", \"md\", \"html\", \"css\", \"yaml\", \"yml\", \"conf\")\n",
    "    glob_pattern = \"**/*.{\" + \",\".join(extensions) + \"}\"\n",
    "    print(f\"Using glob pattern: {glob_pattern}\")\n",
    "\n",
    "    # Find all matching files\n",
    "    matching_files = []\n",
    "    for ext in extensions:\n",
    "        matching_files.extend(glob.glob(os.path.join(directory, f\"**/*.{ext}\"), recursive=True))\n",
    "    print(f\"Found {len(matching_files)} files:\")\n",
    "    for file in matching_files[:5]:\n",
    "        print(f\"  {file}\")\n",
    "    if len(matching_files) > 5:\n",
    "        print(f\"  ...and {len(matching_files) - 5} more\")\n",
    "\n",
    "    # Load documents\n",
    "    documents = []\n",
    "    for file_path in matching_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            doc = Document(page_content=content, metadata={\"source\": os.path.relpath(file_path, directory)})\n",
    "            documents.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {file_path}: {e}\")\n",
    "\n",
    "    # Add tree structure\n",
    "    tree_content = generate_tree_structure(directory)\n",
    "    documents.append(Document(page_content=tree_content, metadata={\"source\": \"directory_tree.txt\"}))\n",
    "\n",
    "    # Add code flow\n",
    "    flow_content = infer_code_flow(matching_files, directory)\n",
    "    documents.append(Document(page_content=flow_content, metadata={\"source\": \"code_flow.txt\"}))\n",
    "\n",
    "    # Debug: Count files per subfolder\n",
    "    subfolders = set()\n",
    "    for doc in documents:\n",
    "        source = doc.metadata.get(\"source\", \"\")\n",
    "        if source not in [\"directory_tree.txt\", \"code_flow.txt\"]:\n",
    "            subfolder = os.path.dirname(source)\n",
    "            subfolders.add(subfolder if subfolder else \"root\")\n",
    "\n",
    "    print(f\"Loaded {len(documents)} files across {len(subfolders)} subfolders:\")\n",
    "    for subfolder in sorted(subfolders):\n",
    "        if subfolder == \"root\":\n",
    "            file_count = sum(1 for doc in documents \n",
    "                            if \"/\" not in doc.metadata.get(\"source\", \"\") \n",
    "                            and doc.metadata[\"source\"] not in [\"directory_tree.txt\", \"code_flow.txt\"])\n",
    "        else:\n",
    "            file_count = sum(1 for doc in documents \n",
    "                            if doc.metadata.get(\"source\", \"\").startswith(subfolder + \"/\") \n",
    "                            and doc.metadata[\"source\"] not in [\"directory_tree.txt\", \"code_flow.txt\"])\n",
    "        if file_count > 0:\n",
    "            print(f\"  {subfolder}: {file_count} files\")\n",
    "\n",
    "    # Split into chunks with optimized size\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Loaded {len(documents)} files, split into {len(split_docs)} chunks\")\n",
    "    return split_docs\n",
    "\n",
    "# # Test with otter-detection\n",
    "# sample_dir = \"otter-detection\"\n",
    "# print(f\"Testing with directory: {sample_dir}\")\n",
    "# docs = load_documents(sample_dir)\n",
    "\n",
    "# # Verify\n",
    "# assert len(docs) > 0, f\"No documents loaded from {sample_dir}! Check directory and permissions.\"\n",
    "# subfolder_count = len(set(os.path.dirname(doc.metadata.get(\"source\", \"\")) for doc in docs \n",
    "#                          if doc.metadata[\"source\"] not in [\"directory_tree.txt\", \"code_flow.txt\"]))\n",
    "# print(f\"Test passed: Loaded {len(docs)} chunks from {subfolder_count} subfolder(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create Vector Store\n",
    "# This is like building a library index for quick reference\n",
    "def create_vector_store(docs, persist_dir=\"./chroma_db\"):\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"mxbai-embed-large\",\n",
    "        # base_url=\"http://localhost:11434\"  # Ensure Ollama is running\n",
    "    )\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "    print(f\"Vector store created at {persist_dir}\")\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Application State and Enhanced Agent\n",
    "# This is the student's notebook, tracking progress through the development lifecycle\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    documents: List[Document]\n",
    "    response: str\n",
    "    stage: str  # Track development stage (e.g., planning, coding, testing)\n",
    "    test_results: List[bool]  # Store test outcomes\n",
    "\n",
    "\n",
    "def teaching_agent(state: AgentState, llm):\n",
    "    stages = [\"Planning\", \"Coding\", \"Testing\", \"Deployment\"]\n",
    "    if \"stage\" not in state or not state[\"stage\"]:\n",
    "        state[\"stage\"] = stages[0]  # Start with Planning\n",
    "    \n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in state[\"documents\"]]) if state[\"documents\"] else \"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    **Role**: You are an expert software architect and educator specializing in codebase analysis and explanation.\n",
    "    \n",
    "    **Current Development Stage**: {state['stage']}\n",
    "    \n",
    "    **User Query Analysis**:\n",
    "    - Original query: \"{state['query']}\"\n",
    "    - Interpreted intent: [Your interpretation of what the user really needs to know]\n",
    "    \n",
    "    **Code Context Analysis**:\n",
    "    {context if context else \"No relevant code context found\"}\n",
    "    \n",
    "    **Task Requirements**:\n",
    "    1. Architectural Breakdown:\n",
    "       - Identify key components/modules in the codebase\n",
    "       - Explain their relationships and data flow\n",
    "       - Highlight any design patterns used\n",
    "    \n",
    "    2. Stage-Specific Guidance:\n",
    "       {{\n",
    "       \"Planning\": \"Focus on overall architecture and requirements\",\n",
    "       \"Coding\": \"Explain implementation details and best practices\",\n",
    "       \"Testing\": \"Highlight testable components and suggest test cases\",\n",
    "       \"Deployment\": \"Discuss deployment considerations and infrastructure\"\n",
    "       }}[{state['stage']}]\n",
    "    \n",
    "    3. User-Level Adaptation:\n",
    "       - Assess the user's likely skill level based on their query\n",
    "       - Adjust technical depth accordingly\n",
    "       - Use analogies where helpful\n",
    "    \n",
    "    **Response Format**:\n",
    "    - Start with 1-sentence summary\n",
    "    - Then provide detailed breakdown\n",
    "    - End with actionable next steps\n",
    "    \n",
    "    **Special Instructions**:\n",
    "    - Never say \"based on the context\" or similar phrases\n",
    "    - If information is incomplete, state what's missing\n",
    "    - Use markdown formatting for code blocks and lists\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return {\n",
    "        \"response\": response.content,\n",
    "        \"stage\": state[\"stage\"],\n",
    "        \"test_results\": state.get(\"test_results\", [])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Test Code and Progress Stages\n",
    "def test_stage(state: AgentState, llm):\n",
    "    if state[\"stage\"] == \"Testing\":\n",
    "        test_prompt = f\"Given this code context:\\n{state['response']}\\nSuggest and evaluate a test case.\"\n",
    "        test_response = llm.invoke(test_prompt)\n",
    "        test_passed = \"pass\" in test_response.content.lower()  # Simple heuristic\n",
    "        state[\"test_results\"].append(test_passed)\n",
    "        print(f\"Test result: {'Passed' if test_passed else 'Failed'}\")\n",
    "    return state\n",
    "\n",
    "def next_stage(state: AgentState):\n",
    "    stages = [\"Planning\", \"Coding\", \"Testing\", \"Deployment\"]\n",
    "    current_idx = stages.index(state[\"stage\"])\n",
    "    if current_idx < len(stages) - 1:\n",
    "        state[\"stage\"] = stages[current_idx + 1]\n",
    "        print(f\"Moving to stage: {state['stage']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: /home/saurabh-nitro/projects/AgenticAI/CodeExplorerRAG/otter-detection\n",
      "Using glob pattern: **/*.{py,js,jsx,ts,java,c,cpp,cs,go,rs,php,rb,sh,txt,md,html,css,yaml,yml,conf}\n",
      "Found 71 files:\n",
      "  otter-detection/src/main.py\n",
      "  otter-detection/src/decoder.py\n",
      "  otter-detection/src/server.py\n",
      "  otter-detection/src/analyse.py\n",
      "  otter-detection/src/tracker.py\n",
      "  ...and 66 more\n",
      "Loaded 73 files across 18 subfolders:\n",
      "  nginx: 1 files\n",
      "  root: 2 files\n",
      "  server/static/devel: 39 files\n",
      "  server/static/devel/src: 37 files\n",
      "  server/static/devel/src/live: 8 files\n",
      "  server/static/devel/src/live/unused: 3 files\n",
      "  server/static/devel/src/monitor: 4 files\n",
      "  server/static/devel/src/mwc: 9 files\n",
      "  server/static/devel/src/recorder: 9 files\n",
      "  server/static/devel/src/recorder/unused: 1 files\n",
      "  src: 11 files\n",
      "  src/fan_controller: 1 files\n",
      "  src/recorder: 2 files\n",
      "  static: 18 files\n",
      "  static/assets: 2 files\n",
      "  static/recorder: 11 files\n",
      "  static/recorder/unused: 6 files\n",
      "  static/recorder/unused/lib: 3 files\n",
      "Loaded 73 files, split into 1076 chunks\n",
      "Vector store created at ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "code_directory=\"otter-detection\"\n",
    "persist_dir=\"./chroma_db\"\n",
    "if not os.path.exists(persist_dir):\n",
    "    docs = load_documents(code_directory)\n",
    "    if docs:\n",
    "        create_vector_store(docs, persist_dir)\n",
    "    else:\n",
    "        print(\"No code files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "def load_chroma_retriever(persist_dir: str = \"./chroma_db\"):\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"mxbai-embed-large\",\n",
    "    )\n",
    "\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=persist_dir,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    \n",
    "    return vector_store.as_retriever()\n",
    "\n",
    "# Initialize the retriever tool\n",
    "retriever = load_chroma_retriever()\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"codebase_retriever\",\n",
    "    \"Search for information about the codebase architecture and implementation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Build the Workflow\n",
    "# This is the lesson plan, guiding you through the lifecycle\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "def build_workflow(llm):\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Modified retrieve node to maintain Document structure\n",
    "    workflow.add_node(\"retrieve\", lambda state: {\n",
    "        \"documents\": [\n",
    "            Document(page_content=content) \n",
    "            for content in retriever_tool.run(state[\"query\"]).split(\"\\n\\n\")  # Simple split, adjust as needed\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Rest of your workflow remains the same\n",
    "    workflow.add_node(\"teach\", lambda state: teaching_agent(state, llm))\n",
    "    # workflow.add_node(\"test\", lambda state: test_stage(state, llm))\n",
    "    # workflow.add_node(\"progress\", next_stage)\n",
    "    \n",
    "    # workflow.set_entry_point(\"retrieve\")\n",
    "    workflow.add_edge(START, \"retrieve\")\n",
    "    workflow.add_edge(\"retrieve\", \"teach\")\n",
    "    workflow.add_edge(\"teach\", END)\n",
    "    # workflow.add_edge(\"test\", \"progress\")\n",
    "    # workflow.add_conditional_edges(\n",
    "    #     \"progress\",\n",
    "    #     lambda state: END if state[\"stage\"] == \"Deployment\" else \"retrieve\"\n",
    "    # )\n",
    "    \n",
    "    graph =  workflow.compile()\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "# # Test workflow setup\n",
    "# workflow = build_workflow(llm, \"./chroma_db\")\n",
    "# print(\"Workflow built successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete. Your AI teacher is ready!\n"
     ]
    }
   ],
   "source": [
    "llm = setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = build_workflow(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Run the Application with Progress Tracking\n",
    "def run_app(query: str):\n",
    "    state = {\"query\": query, \"test_results\": []}\n",
    "    stages_completed = []\n",
    "    times = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    state = app.invoke(state)\n",
    "    stages_completed.append(state[\"stage\"])\n",
    "    times.append(time.time() - start_time)\n",
    "    print(f\"\\nStage: {state['stage']}\\nResponse: {state['response']}\")\n",
    "\n",
    "    return state, stages_completed, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage: Planning\n",
      "Response: ## Overview of the React Code\n",
      "\n",
      "The provided React code is a collection of components that seem to be part of a larger application for displaying and analyzing data from a database, specifically InfluxDB. The components include:\n",
      "\n",
      "1. `DataChart`: A chart component that displays data from InfluxDB.\n",
      "2. `DataGridAndChart`: A component that combines a data grid and a chart.\n",
      "3. `DataGrid`: A component that displays data in a grid format.\n",
      "4. `Thumbnail`: A component that displays a thumbnail image with overlay text.\n",
      "\n",
      "## How the Code Works\n",
      "\n",
      "1. **DataChart**: This component uses the `AgCharts` library to create a chart. It fetches data from InfluxDB using the `queryInflux` function and updates the chart with the fetched data. The chart displays data for a specific field and duration.\n",
      "2. **DataGridAndChart**: This component combines a data grid and a chart. It uses the `DataGrid` and `DataChart` components and passes props to them. It also handles state changes for the grid and chart.\n",
      "3. **DataGrid**: This component uses the `ag-grid-community` library to create a data grid. It fetches data from InfluxDB using the `queryInflux` function and updates the grid with the fetched data.\n",
      "4. **Thumbnail**: This component displays a thumbnail image with overlay text. It does not seem to be directly related to the database or data analysis.\n",
      "\n",
      "## Components Used in the Database\n",
      "\n",
      "The components that interact with the database are:\n",
      "\n",
      "1. **DataChart**: Fetches data from InfluxDB using the `queryInflux` function.\n",
      "2. **DataGrid**: Fetches data from InfluxDB using the `queryInflux` function.\n",
      "\n",
      "## Breaking Down the Code\n",
      "\n",
      "Here's a breakdown of the code:\n",
      "\n",
      "### DataChart\n",
      "\n",
      "* **State**: The component uses several state variables: `chart`, `loading`, `title`, and `axes`.\n",
      "* **Effects**: The component uses several effects:\n",
      "\t+ One effect creates the chart using `AgCharts`.\n",
      "\t+ Another effect updates the chart with new data when the `time` prop changes.\n",
      "\t+ Another effect fetches data from InfluxDB when the `field` and `duration` props change.\n",
      "* **Props**: The component accepts several props: `style`, `field`, `fieldName`, `duration`, `device_numbers`, and `time`.\n",
      "\n",
      "### DataGridAndChart\n",
      "\n",
      "* **State**: The component uses several state variables: `mode`, `duration`, `field`, `fieldName`, `deviceNumbers`, and `time`.\n",
      "* **Effects**: The component uses one effect to update the `deviceNumbers` state when the `device_number` prop changes.\n",
      "* **Props**: The component accepts several props: `style`, `device_number`.\n",
      "\n",
      "### DataGrid\n",
      "\n",
      "* **State**: The component uses several state variables: `grid`.\n",
      "* **Effects**: The component uses one effect to create the grid using `ag-grid-community`.\n",
      "* **Props**: The component accepts several props: `device_number`, `duration`, `mode`, `field`, `setField`, `setFieldName`, `setDeviceNumbers`, `setTime`, and `style`.\n",
      "\n",
      "## Insights Through the Database\n",
      "\n",
      "The database seems to be an InfluxDB instance, which is a time-series database. The components fetch data from the database using the `queryInflux` function, which suggests that the data is stored in a time-series format.\n",
      "\n",
      "The data seems to be related to devices, as there are props and state variables that reference device numbers and names. The data also seems to be related to fields, as there are props and state variables that reference field names and values.\n",
      "\n",
      "The components seem to be designed to display and analyze data from the database, with features like charting and grid display. The components also seem to be designed to handle state changes and updates, which suggests that the application is interactive and dynamic.\n",
      "\n",
      "Overall, the code suggests that the application is a data analysis and visualization tool, designed to work with time-series data from InfluxDB. The components are designed to display and analyze data, and to handle state changes and updates in a dynamic and interactive way.\n"
     ]
    }
   ],
   "source": [
    "# Run with a sample query\n",
    "query = \"tell me about the react code in databse, how its working\"\n",
    "code_dir = \"otter-detection\"\n",
    "final_state, stages, times = run_app(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 8: Plot Progress Graph\n",
    "# # Visualize how long each stage took\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(stages, times, marker='o', linestyle='-', color='b')\n",
    "# plt.title(\"Software Development Lifecycle Progress\")\n",
    "# plt.xlabel(\"Stage\")\n",
    "# plt.ylabel(\"Time (seconds)\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Display test results\n",
    "# print(\"\\nTest Results:\")\n",
    "# for i, result in enumerate(final_state[\"test_results\"]):\n",
    "#     print(f\"Test {i+1}: {'Passed' if result else 'Failed'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
