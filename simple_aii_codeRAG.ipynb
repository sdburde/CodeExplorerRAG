{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for our RAG application and teaching agent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "import glob\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "import time  # For timing stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setup Environment and LLM\n",
    "# This is like setting up your classroom with the right tools\n",
    "def setup_environment():\n",
    "    load_dotenv()\n",
    "    if not os.getenv(\"GROQ_API_KEY\"):\n",
    "        raise ValueError(\"Please set GROQ_API_KEY in your .env file!\")\n",
    "    llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    print(\"Environment setup complete. Your AI teacher is ready!\")\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete. Your AI teacher is ready!\n"
     ]
    }
   ],
   "source": [
    "llm = setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import re\n",
    "\n",
    "def generate_tree_structure(directory):\n",
    "    \"\"\"Generate a textual representation of the directory tree.\"\"\"\n",
    "    tree = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        level = root.replace(directory, '').count(os.sep)\n",
    "        indent = '  ' * level\n",
    "        tree.append(f\"{indent}{os.path.basename(root)}/\")\n",
    "        for f in files:\n",
    "            tree.append(f\"{indent}  {f}\")\n",
    "    return \"\\n\".join(tree)\n",
    "\n",
    "def infer_code_flow(files, directory):\n",
    "    \"\"\"Basic inference of code flow by looking at imports/requires.\"\"\"\n",
    "    flow = []\n",
    "    import_patterns = {\n",
    "        'py': r\"import\\s+[\\w.]+\\s*(?:as\\s+\\w+)?|from\\s+[\\w.]+\\s+import\\s+[\\w.*]+\",\n",
    "        'js': r\"import\\s+.*?\\s+from\\s+['\\\"].*?['\\\"]|require\\(['\\\"].*?['\\\"]\\)\",\n",
    "        'jsx': r\"import\\s+.*?\\s+from\\s+['\\\"].*?['\\\"]|require\\(['\\\"].*?['\\\"]\\)\"\n",
    "    }\n",
    "    \n",
    "    for file_path in files:\n",
    "        ext = file_path.rsplit('.', 1)[-1] if '.' in file_path else ''\n",
    "        if ext in import_patterns:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                imports = re.findall(import_patterns[ext], content)\n",
    "                if imports:\n",
    "                    rel_path = os.path.relpath(file_path, directory)\n",
    "                    flow.append(f\"{rel_path} depends on:\")\n",
    "                    for imp in imports:\n",
    "                        flow.append(f\"  - {imp.strip()}\")\n",
    "            except Exception as e:\n",
    "                flow.append(f\"Error analyzing {file_path}: {e}\")\n",
    "    return \"\\n\".join(flow) if flow else \"No detectable dependencies found.\"\n",
    "\n",
    "def load_documents(directory=\"code_folder\"):\n",
    "    \"\"\"Load code files, tree, and flow from the directory.\"\"\"\n",
    "    # Verify directory exists\n",
    "    abs_dir = os.path.abspath(directory)\n",
    "    if not os.path.isdir(abs_dir):\n",
    "        print(f\"Error: Directory '{abs_dir}' does not exist!\")\n",
    "        return []\n",
    "    print(f\"Scanning directory: {abs_dir}\")\n",
    "\n",
    "    # Define supported extensions\n",
    "    extensions = (\"py\", \"js\", \"jsx\", \"ts\", \"java\", \"c\", \"cpp\", \"cs\", \"go\", \"rs\", \n",
    "                  \"php\", \"rb\", \"sh\", \"txt\", \"md\", \"html\", \"css\", \"yaml\", \"yml\", \"conf\")\n",
    "    glob_pattern = \"**/*.{\" + \",\".join(extensions) + \"}\"\n",
    "    print(f\"Using glob pattern: {glob_pattern}\")\n",
    "\n",
    "    # Find all matching files\n",
    "    matching_files = []\n",
    "    for ext in extensions:\n",
    "        matching_files.extend(glob.glob(os.path.join(directory, f\"**/*.{ext}\"), recursive=True))\n",
    "    print(f\"Found {len(matching_files)} files:\")\n",
    "    for file in matching_files[:5]:\n",
    "        print(f\"  {file}\")\n",
    "    if len(matching_files) > 5:\n",
    "        print(f\"  ...and {len(matching_files) - 5} more\")\n",
    "\n",
    "    # Load documents\n",
    "    documents = []\n",
    "\n",
    "\n",
    "    # Add tree structure\n",
    "    tree_content = generate_tree_structure(directory)\n",
    "    documents.append(Document(page_content=tree_content, metadata={\"source\": \"files tree\"}))\n",
    "\n",
    "    # Add code flow\n",
    "    flow_content = infer_code_flow(matching_files, directory)\n",
    "    documents.append(Document(page_content=flow_content, metadata={\"source\": \"code flow\"}))\n",
    "\n",
    "\n",
    "    for file_path in matching_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            doc = Document(page_content=content, metadata={\"source\": os.path.relpath(file_path, directory)})\n",
    "            documents.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {file_path}: {e}\")\n",
    "\n",
    "\n",
    "    # # Debug: Count files per subfolder\n",
    "    # subfolders = set()\n",
    "    # for doc in documents:\n",
    "    #     source = doc.metadata.get(\"source\", \"\")\n",
    "    #     if source not in [\"directory_tree.txt\", \"code_flow.txt\"]:\n",
    "    #         subfolder = os.path.dirname(source)\n",
    "    #         subfolders.add(subfolder if subfolder else \"root\")\n",
    "\n",
    "    # print(f\"Loaded {len(documents)} files across {len(subfolders)} subfolders:\")\n",
    "    # for subfolder in sorted(subfolders):\n",
    "    #     if subfolder == \"root\":\n",
    "    #         file_count = sum(1 for doc in documents \n",
    "    #                         if \"/\" not in doc.metadata.get(\"source\", \"\") \n",
    "    #                         and doc.metadata[\"source\"] not in [\"directory_tree.txt\", \"code_flow.txt\"])\n",
    "    #     else:\n",
    "    #         file_count = sum(1 for doc in documents \n",
    "    #                         if doc.metadata.get(\"source\", \"\").startswith(subfolder + \"/\") \n",
    "    #                         and doc.metadata[\"source\"] not in [\"directory_tree.txt\", \"code_flow.txt\"])\n",
    "    #     if file_count > 0:\n",
    "    #         print(f\"  {subfolder}: {file_count} files\")\n",
    "\n",
    "    # # Save all documents to a single file\n",
    "    # with open(\"codes_file.txt\", \"w\", encoding='utf-8') as f:\n",
    "    #     for doc in documents:\n",
    "    #         print(doc)  # Print the full Document object\n",
    "    #         print(doc.page_content)  # Print the content\n",
    "    #         f.write(f\"Source: {doc.metadata['source']}\\n\\n{doc.page_content}\\n\\n{'='*50}\\n\\n\")\n",
    "\n",
    "    # Split into chunks with optimized size\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Loaded {len(documents)} files, split into {len(split_docs)} chunks\")\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(docs, persist_dir=\"./chroma_db\"):\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"mxbai-embed-large\",\n",
    "    )\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "    print(f\"Vector store created at {persist_dir}\")\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "def load_chroma_retriever(persist_dir: str = \"./chroma_db\"):\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"mxbai-embed-large\",\n",
    "    )\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=persist_dir,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    return vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: /home/saurabh-nitro/projects/AgenticAI/CodeExplorerRAG/otter-detection\n",
      "Using glob pattern: **/*.{py,js,jsx,ts,java,c,cpp,cs,go,rs,php,rb,sh,txt,md,html,css,yaml,yml,conf}\n",
      "Found 71 files:\n",
      "  otter-detection/src/main.py\n",
      "  otter-detection/src/decoder.py\n",
      "  otter-detection/src/server.py\n",
      "  otter-detection/src/analyse.py\n",
      "  otter-detection/src/tracker.py\n",
      "  ...and 66 more\n",
      "Loaded 73 files, split into 1076 chunks\n",
      "Vector store created at ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "code_directory=\"otter-detection\"\n",
    "persist_dir=\"./chroma_db\"\n",
    "if not os.path.exists(persist_dir):\n",
    "    docs = load_documents(code_directory)\n",
    "    if docs:\n",
    "        create_vector_store(docs, persist_dir)\n",
    "    else:\n",
    "        print(\"No code files found!\")\n",
    "# Initialize the retriever tool\n",
    "retriever = load_chroma_retriever()\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"codebase_retriever\",\n",
    "    \"Search for information about the codebase related componets codes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the database with a sample query\n",
    "query = \"directory_tree\"\n",
    "retrieved_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='4f0bb4cb-47be-4a19-a7f4-ce414eeae3a6', metadata={'source': 'static/recorder/unused/lib/mwc.min.js'}, page_content='n=r.shadowRoot;if(n)return void c(n,t);if(\"content\"==r.localName){for(var o=r,a=o.getDistributedNodes?o.getDistributedNodes():[],d=0;d<a.length;d++)c(a[d],t);return}if(\"slot\"==r.localName){for(var s=r,l=s.assignedNodes?s.assignedNodes({flatten:!0}):[],u=0;u<l.length;u++)c(l[u],t);return}}for(var p=e.firstChild;null!=p;)c(p,t),p=p.nextSibling}function d(e){if(!e.querySelector(\"style#inert-style, link#inert-style\")){var t=document.createElement(\"style\");t.setAttribute(\"id\",\"inert-style\"),t.textContent=\"\\\\n[inert] {\\\\n  pointer-events: none;\\\\n  cursor: default;\\\\n}\\\\n\\\\n[inert], [inert] * {\\\\n  -webkit-user-select: none;\\\\n  -moz-user-select: none;\\\\n  -ms-user-select: none;\\\\n  user-select: none;\\\\n}\\\\n\",e.appendChild(t)}}}();'),\n",
       " Document(id='c127169d-fd84-49ef-b117-ece25e982c1a', metadata={'source': 'static/assets/mwc.min.js'}, page_content=\"inertSubroot.managedNodes.forEach(function(savedInertNode){this._manageNode(savedInertNode.node);},this);}},{key:'_onMutation',value:function _onMutation(records,self){records.forEach(function(record){var target=record.target;if(record.type==='childList'){slice.call(record.addedNodes).forEach(function(node){this._makeSubtreeUnfocusable(node);},this);slice.call(record.removedNodes).forEach(function(node){this._unmanageSubtree(node);},this);}else if(record.type==='attributes'){if(record.attributeName==='tabindex'){this._manageNode(target);}else if(target!==this._rootElement&&record.attributeName==='inert'&&target.hasAttribute('inert')){this._adoptInertRoot(target);var inertSubroot=this._inertManager.getInertRoot(target);this._managedNodes.forEach(function(managedNode){if(target.contains(managedNode.node)){inertSubroot._manageNode(managedNode.node);}});}}},this);}},{key:'managedNodes',get:function get(){return new Set(this._managedNodes);}},{key:'hasSavedAriaHidden',get:function get(){return this._savedAriaHidden!==null;}},{key:'savedAriaHidden',set:function set(ariaHidden){this._savedAriaHidden=ariaHidden;},get:function get(){return this._savedAriaHidden;}}]);return InertRoot;}();var InertNode=function(){function InertNode(node,inertRoot){_classCallCheck(this,InertNode);this._node=node;this._overrodeFocusMethod=false;this._inertRoots=new Set([inertRoot]);this._savedTabIndex=null;this._destroyed=false;this.ensureUntabbable();}\\n_createClass(InertNode,[{key:'destructor',value:function destructor(){this._throwIfDestroyed();if(this._node&&this._node.nodeType===Node.ELEMENT_NODE){var element=this._node;if(this._savedTabIndex!==null){element.setAttribute('tabindex',this._savedTabIndex);}else{element.removeAttribute('tabindex');}\\nif(this._overrodeFocusMethod){delete element.focus;}}\"),\n",
       " Document(id='d0d71b7a-d3f5-497c-a821-018bf85f71a8', metadata={'source': 'src/recorder/playback.py'}, page_content='def get_video_list_and_disk_usage():\\n    paths = glob(f\"{EXTERNAL_ROOT}/*.m??\")\\n    paths_by_basename = {basename(x): x for x in paths}\\n    for x in glob(f\"{INTERNAL_ROOT}/*.m??\"):\\n        bname = basename(x)\\n        if bname not in paths_by_basename:\\n            paths_by_basename[bname] = x\\n    # Sort by basename\\n    paths = sorted(list(paths_by_basename.items()), key=lambda x: x[0])\\n    video_list = [dict(path=bname, size=getsize(p)) for bname, p in paths]\\n    usage = disk_usage(EXTERNAL_ROOT)\\n    return dict(\\n        list=video_list,\\n        disk_usage=dict(total=usage.total, used=usage.used),\\n    )\\n\\n\\nIOLOOP = IOLoop.current()\\n\\n\\ndef parse_launch(launch):\\n    launch = \" \".join(launch.split())\\n    print(launch)\\n    return Gst.parse_launch(launch)\\n\\n\\nclass PipelineHandler(WebSocketHandler):\\n\\n    def check_origin(self, x):\\n        if x.startswith(\"http://localhost:\"):\\n            return True\\n        return re.match(r\"^https://\\\\S+.v3nity.com$\", x)\\n\\n    def open(self):\\n        print(\"open\")\\n        self.pipeline = None\\n        self.pipeline2 = None\\n        self.duration = None\\n        self.start = None\\n\\n    def on_close(self):\\n        print(\"close\")\\n        self.cleanup()\\n\\n    def cleanup(self):\\n        if self.pipeline:\\n            self.pipeline.set_state(Gst.State.NULL)\\n        if self.pipeline2:\\n            self.pipeline2.set_state(Gst.State.NULL)\\n\\n    def seek(self, position):\\n        # Flush transcoding pipeline\\n        sink_pad = self.pipeline2.get_by_name(\"appsink\").get_static_pad(\"sink\")\\n        sink_pad.send_event(Gst.Event.new_flush_start())\\n        self.pipeline.seek_simple(\\n            Gst.Format.TIME, Gst.SeekFlags.FLUSH | Gst.SeekFlags.KEY_UNIT,\\n            int(position * 1e9),\\n        )\\n        sink_pad.send_event(Gst.Event.new_flush_stop(False))\\n\\n    def on_message(self, message):\\n\\n        # message = json_decode(message)\\n        message = msgpack.loads(message)\\n        if message is None:  # Keep alive ping\\n            return'),\n",
       " Document(id='13c3a015-289a-431a-ad1a-f9dc4f819418', metadata={'source': 'static/recorder/unused/lib/mwc.min.js'}, page_content='Ji(i,[{key:\"setInert\",value:function(e,t){if(t){if(this._inertRoots.has(e))return;var i=new r(e,this);if(e.setAttribute(\"inert\",\"\"),this._inertRoots.set(e,i),!this._document.body.contains(e))for(var n=e.parentNode;n;)11===n.nodeType&&d(n),n=n.parentNode}else{if(!this._inertRoots.has(e))return;this._inertRoots.get(e).destructor(),this._inertRoots.delete(e),e.removeAttribute(\"inert\")}}},{key:\"getInertRoot\",value:function(e){return this._inertRoots.get(e)}},{key:\"register\",value:function(e,t){var i=this._managedNodes.get(e);return void 0!==i?i.addInertRoot(t):i=new n(e,t),this._managedNodes.set(e,i),i}},{key:\"deregister\",value:function(e,t){var i=this._managedNodes.get(e);return i?(i.removeInertRoot(t),i.destroyed&&this._managedNodes.delete(e),i):null}},{key:\"_onDocumentLoaded\",value:function(){e.call(this._document.querySelectorAll(\"[inert]\")).forEach((function(e){this.setInert(e,!0)}),this),this._observer.observe(this._document.body||this._document.documentElement,{attributes:!0,subtree:!0,childList:!0})}},{key:\"_watchForInert\",value:function(i,r){var n=this;i.forEach((function(i){switch(i.type){case\"childList\":e.call(i.addedNodes).forEach((function(i){if(i.nodeType===Node.ELEMENT_NODE){var r=e.call(i.querySelectorAll(\"[inert]\"));t.call(i,\"[inert]\")&&r.unshift(i),r.forEach((function(e){this.setInert(e,!0)}),n)}}),n);break;case\"attributes\":if(\"inert\"!==i.attributeName)return;var r=i.target,o=r.hasAttribute(\"inert\");n.setInert(r,o)}}),this)}}]),i}();if(!HTMLElement.prototype.hasOwnProperty(\"inert\")){var a=new o(document);Object.defineProperty(HTMLElement.prototype,\"inert\",{enumerable:!0,get:function(){return this.hasAttribute(\"inert\")},set:function(e){a.setInert(this,e)}})}}function c(e,t,i){if(e.nodeType==Node.ELEMENT_NODE){var r=e;t&&t(r);var n=r.shadowRoot;if(n)return void c(n,t);if(\"content\"==r.localName){for(var o=r,a=o.getDistributedNodes?o.getDistributedNodes():[],d=0;d<a.length;d++)c(a[d],t);return}if(\"slot\"==r.localName){for(var')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the database with a sample query\n",
    "query = \"code_flow\"\n",
    "retrieved_docs = retriever.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5711ab98-5fa7-4aaa-af7f-96539cad6310', metadata={'source': 'static/recorder/unused/lib/msgpack.min.js'}, page_content='o[1];return{value:o[0]?o[1]:void 0,done:!0}}([o,a])}}},j=function(e){if(!Symbol.asyncIterator)throw new TypeError(\"Symbol.asyncIterator is not defined.\");var t,n=e[Symbol.asyncIterator];return n?n.call(e):(e=\"function\"==typeof __values?__values(e):e[Symbol.iterator](),t={},r(\"next\"),r(\"throw\"),r(\"return\"),t[Symbol.asyncIterator]=function(){return this},t);function r(n){t[n]=e[n]&&function(t){return new Promise((function(r,i){!function(e,t,n,r){Promise.resolve(r).then((function(t){e({value:t,done:n})}),t)}(r,i,(t=e[n](t)).done,t.value)}))}}},F=function(e){return this instanceof F?(this.v=e,this):new F(e)},W=function(e,t,n){if(!Symbol.asyncIterator)throw new TypeError(\"Symbol.asyncIterator is not defined.\");var r,i=n.apply(e,t||[]),o=[];return r={},s(\"next\"),s(\"throw\"),s(\"return\"),r[Symbol.asyncIterator]=function(){return this},r;function s(e){i[e]&&(r[e]=function(t){return new Promise((function(n,r){o.push([e,t,n,r])>1||a(e,t)}))})}function a(e,t){try{(n=i[e](t)).value instanceof F?Promise.resolve(n.value.v).then(c,h):u(o[0][2],n)}catch(e){u(o[0][3],e)}var n}function c(e){a(\"next\",e)}function h(e){a(\"throw\",e)}function u(e,t){e(t),o.shift(),o.length&&a(o[0][0],o[0][1])}},R=new DataView(new ArrayBuffer(0)),V=new Uint8Array(R.buffer),K=function(){try{R.getInt8(0)}catch(e){return e.constructor}throw new Error(\"never reached\")}(),N=new K(\"Insufficient data\"),H=new O,G=function(){function e(e,t,r,i,o,s,a,c){void 0===e&&(e=A.defaultCodec),void 0===t&&(t=void 0),void 0===r&&(r=n),void 0===i&&(i=n),void 0===o&&(o=n),void 0===s&&(s=n),void 0===a&&(a=n),void 0===c&&(c=H),this.extensionCodec=e,this.context=t,this.maxStrLength=r,this.maxBinLength=i,this.maxArrayLength=o,this.maxMapLength=s,this.maxExtLength=a,this.keyDecoder=c,this.totalPos=0,this.pos=0,this.view=R,this.bytes=V,this.headByte=-1,this.stack=[]}return'),\n",
       " Document(id='237ec0e0-5454-4669-8d69-4e938b426d7e', metadata={'source': 'static/recorder/unused/lib/mwc.min.js'}, page_content='t,i,r=Bu(n);function n(){var e;return c(this,n),(e=r.apply(this,arguments)).mdcFoundationClass=Tu,e.value=\"\",e.type=\"text\",e.placeholder=\"\",e.label=\"\",e.icon=\"\",e.iconTrailing=\"\",e.disabled=!1,e.required=!1,e.minLength=-1,e.maxLength=-1,e.outlined=!1,e.helper=\"\",e.validateOnInitialRender=!1,e.validationMessage=\"\",e.autoValidate=!1,e.pattern=\"\",e.min=\"\",e.max=\"\",e.step=null,e.size=null,e.helperPersistent=!1,e.charCounter=!1,e.endAligned=!1,e.prefix=\"\",e.suffix=\"\",e.name=\"\",e.readOnly=!1,e.autocapitalize=\"\",e.outlineOpen=!1,e.outlineWidth=0,e.isUiValid=!0,e.focused=!1,e._validity=Uu(),e.validityTransform=null,e}return a(n,[{key:\"validity\",get:function(){return this._checkValidity(this.value),this._validity}},{key:\"willValidate\",get:function(){return this.formElement.willValidate}},{key:\"selectionStart\",get:function(){return this.formElement.selectionStart}},{key:\"selectionEnd\",get:function(){return this.formElement.selectionEnd}},{key:\"focus\",value:function(){var e=new CustomEvent(\"focus\");this.formElement.dispatchEvent(e),this.formElement.focus()}},{key:\"blur\",value:function(){var e=new CustomEvent(\"blur\");this.formElement.dispatchEvent(e),this.formElement.blur()}},{key:\"select\",value:function(){this.formElement.select()}},{key:\"setSelectionRange\",value:function(e,t,i){this.formElement.setSelectionRange(e,t,i)}},{key:\"update\",value:function(e){e.has(\"autoValidate\")&&this.mdcFoundation&&this.mdcFoundation.setValidateOnValueChange(this.autoValidate),e.has(\"value\")&&\"string\"!=typeof this.value&&(this.value=\"\".concat(this.value)),bt(h(n.prototype),\"update\",this).call(this,e)}},{key:\"setFormData\",value:function(e){this.name&&e.append(this.name,this.value)}},{key:\"render\",value:function(){var'),\n",
       " Document(id='2e0cd427-5f22-44dc-a0b9-1e63556a2d59', metadata={'source': 'static/assets/msgpack.2.8.0.min.js'}, page_content='i;switch(r=0,i&&(o=[2&o[0],i.value]),o[0]){case 0:case 1:i=o;break;case 4:return s.label++,{value:o[1],done:!1};case 5:s.label++,r=o[1],o=[0];continue;case 7:o=s.ops.pop(),s.trys.pop();continue;default:if(!(i=s.trys,(i=i.length>0&&i[i.length-1])||6!==o[0]&&2!==o[0])){s=0;continue}if(3===o[0]&&(!i||o[1]>i[0]&&o[1]<i[3])){s.label=o[1];break}if(6===o[0]&&s.label<i[1]){s.label=i[1],i=o;break}if(i&&s.label<i[2]){s.label=i[2],s.ops.push(o);break}i[2]&&s.ops.pop(),s.trys.pop();continue}o=e.call(t,s)}catch(t){o=[6,t],r=0}finally{n=i=0}if(5&o[0])throw o[1];return{value:o[0]?o[1]:void 0,done:!0}}([o,a])}}},at=function(t){if(!Symbol.asyncIterator)throw new TypeError(\"Symbol.asyncIterator is not defined.\");var e,n=t[Symbol.asyncIterator];return n?n.call(t):(t=\"function\"==typeof __values?__values(t):t[Symbol.iterator](),e={},r(\"next\"),r(\"throw\"),r(\"return\"),e[Symbol.asyncIterator]=function(){return this},e);function r(n){e[n]=t[n]&&function(e){return new Promise((function(r,i){(function(t,e,n,r){Promise.resolve(r).then((function(e){t({value:e,done:n})}),e)})(r,i,(e=t[n](e)).done,e.value)}))}}},ht=function(t){return this instanceof ht?(this.v=t,this):new ht(t)},ct=function(t,e,n){if(!Symbol.asyncIterator)throw new TypeError(\"Symbol.asyncIterator is not defined.\");var r,i=n.apply(t,e||[]),o=[];return r={},s(\"next\"),s(\"throw\"),s(\"return\"),r[Symbol.asyncIterator]=function(){return this},r;function s(t){i[t]&&(r[t]=function(e){return new Promise((function(n,r){o.push([t,e,n,r])>1||a(t,e)}))})}function a(t,e){try{(n=i[t](e)).value instanceof ht?Promise.resolve(n.value.v).then(h,c):u(o[0][2],n)}catch(t){u(o[0][3],t)}var n}function h(t){a(\"next\",t)}function c(t){a(\"throw\",t)}function u(t,e){t(e),o.shift(),o.length&&a(o[0][0],o[0][1])}},ut=new DataView(new ArrayBuffer(0)),ft=new Uint8Array(ut.buffer),lt=function(){try{ut.getInt8(0)}catch(t){return t.constructor}throw new Error(\"never reached\")}(),pt=new lt(\"Insufficient data\"),dt=new it,yt=function(){function t(t,e,n,r,i,o,s,a){void'),\n",
       " Document(id='90ac784b-9cf7-4764-a657-54134bb85b0c', metadata={'source': 'static/assets/msgpack.2.8.0.min.js'}, page_content='o[1];return{value:o[0]?o[1]:void 0,done:!0}}([o,a])}}},mt=function(t){return this instanceof mt?(this.v=t,this):new mt(t)},xt=function(t,e,n){if(!Symbol.asyncIterator)throw new TypeError(\"Symbol.asyncIterator is not defined.\");var r,i=n.apply(t,e||[]),o=[];return r={},s(\"next\"),s(\"throw\"),s(\"return\"),r[Symbol.asyncIterator]=function(){return this},r;function s(t){i[t]&&(r[t]=function(e){return new Promise((function(n,r){o.push([t,e,n,r])>1||a(t,e)}))})}function a(t,e){try{(n=i[t](e)).value instanceof mt?Promise.resolve(n.value.v).then(h,c):u(o[0][2],n)}catch(t){u(o[0][3],t)}var n}function h(t){a(\"next\",t)}function c(t){a(\"throw\",t)}function u(t,e){t(e),o.shift(),o.length&&a(o[0][0],o[0][1])}};function Ut(t){return xt(this,arguments,(function(){var e,n,r,i;return bt(this,(function(o){switch(o.label){case 0:e=t.getReader(),o.label=1;case 1:o.trys.push([1,,9,10]),o.label=2;case 2:return[4,mt(e.read())];case 3:return n=o.sent(),r=n.done,i=n.value,r?[4,mt(void 0)]:[3,5];case 4:return[2,o.sent()];case 5:return function(t){if(null==t)throw new Error(\"Assertion Failure: value must not be null nor undefined\")}(i),[4,mt(i)];case 6:return[4,o.sent()];case 7:return o.sent(),[3,2];case 8:return[3,10];case 9:return e.releaseLock(),[7];case 10:return[2]}}))}))}function St(t){return null!=t[Symbol.asyncIterator]?t:Ut(t)}var Et=function(t,e,n,r){return new(n||(n=Promise))((function(i,o){function s(t){try{h(r.next(t))}catch(t){o(t)}}function a(t){try{h(r.throw(t))}catch(t){o(t)}}function h(t){var e;t.done?i(t.value):(e=t.value,e instanceof n?e:new n((function(t){t(e)}))).then(s,a)}h((r=r.apply(t,e||[])).next())}))},Bt=function(t,e){var n,r,i,o,s={label:0,sent:function(){if(1&i[0])throw i[1];return i[1]},trys:[],ops:[]};return o={next:a(0),throw:a(1),return:a(2)},\"function\"==typeof Symbol&&(o[Symbol.iterator]=function(){return this}),o;function a(o){return function(a){return function(o){if(n)throw new TypeError(\"Generator is already')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_905756/1119403825.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "# Search the database with a sample query\n",
    "query = \"react\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='bc22e86a-de30-4f18-b127-c4a9443102dd', metadata={'source': 'server/static/devel/src/live/unused/live-video-player.jsx'}, page_content='\"use strict\"\\n\\nimport React, { useState, useEffect, useRef } from \"react\"\\n\\nexport function LivePage({\\n    selectedDevice\\n}) {\\n    <GridContainer isGridView={selectedDevice == 0} style={{\\n        flex: 1,\\n        width: \"100%\",\\n    }}>\\n        {deviceData.map((x, i) => {\\n            return (selectedDevice == 0 || selectedDevice == i + 1) && <VideoPlayer\\n                key={i}\\n                ref={x => video_player_refs.current[i] = x}\\n                device_number={x.device_number}\\n                ptz={selectedDevice == i + 1}\\n                overlay={enableOverlay}\\n                onClick={_ => {\\n                    console.log(\"Clicked video player\", i)\\n                    list_item_refs.current[i].click()\\n                }}\\n            ></VideoPlayer>\\n        })}\\n    </GridContainer>\\n}'),\n",
       " Document(id='2406db5e-8db6-4cae-a9d2-e01ed6903320', metadata={'source': 'server/static/devel/src/live/unused/video-player.jsx'}, page_content='\"use strict\"\\n\\nimport React, { useState, useEffect, useRef } from \"react\"\\nimport { decode } from \"@msgpack/msgpack\"\\n\\nimport { Snackbar } from \"../mwc/snackbar\"\\nimport { Icon } from \"../mwc/icon\"\\n\\nimport { CircularProgress } from \"../circular-progress\"\\nimport { drawDetections, drawText } from \"./draw\"\\nimport { CameraControl } from \"./camera-control\"\\nimport { getDeviceName } from \"../util\"\\n\\nfunction toDurationString(seconds) { // to DD:HH:MM:SS.fff\\n    const days = Math.round(seconds / 24 / 3600)\\n    let stamp = `${new Date(seconds * 1e3).toISOString().slice(11, 22)}`\\n    return days > 0 ? `${days}d ${stamp}` : stamp\\n}\\n\\nexport function VideoPlayer({ device_number, framerate = 30, ptz, overlay, ...props }) {\\n\\n    function cleanup() {\\n        console.log(`Close WebSocket ${device_number}`)\\n        ws?.close()\\n        video_decoder?.close()\\n        h264_buffer.length = 0\\n    }'),\n",
       " Document(id='5f618116-4807-4b73-ba18-bd4ceab51a1c', metadata={'source': 'code flow'}, page_content='- import React, { useState, useEffect, useRef } from \"react\"\\n  - import { decode } from \"@msgpack/msgpack\"\\n  - import { Snackbar } from \"../mwc/snackbar\"\\n  - import { Icon } from \"../mwc/icon\"\\n  - import { CircularProgress } from \"../circular-progress\"\\n  - import { drawDetections, drawText } from \"./draw\"\\n  - import { CameraControl } from \"./camera-control\"\\n  - import { getDeviceName } from \"../util\"\\nserver/static/devel/src/live/unused/live-video-player.jsx depends on:\\n  - import React, { useState, useEffect, useRef } from \"react\"\\nserver/static/devel/src/monitor/data-grid-and-chart.jsx depends on:\\n  - import React, { useState, useEffect, useRef } from \"react\"\\n  - import { Menu } from \"../mwc/menu\"\\n  - import { DataGrid } from \"./data-grid\"\\n  - import { DataChart } from \"./data-chart\"\\n  - import { useState2 } from \"../util\"\\nserver/static/devel/src/monitor/data-chart.jsx depends on:\\n  - import React, { useState, useEffect, useRef } from \"react\"\\n  - import { queryInflux } from \"../influx\"\\n  - import { color_names, toSizeString, getDeviceName } from \"../util\"\\n  - import { AgCharts } from \"ag-charts-community\"\\nserver/static/devel/src/monitor/data-grid.jsx depends on:\\n  - import React, { useState, useEffect, useRef } from \"react\"\\n  - import { queryInflux } from \"../influx\"\\n  - import { createGrid, themeQuartz } from \"ag-grid-community\"\\nserver/static/devel/src/monitor/data-grid-column-defs.jsx depends on:\\n  - import { toDurationString, toSizeString, toDateString, color_names } from \"../util\"'),\n",
       " Document(id='12832af6-1d39-4237-a56a-495fce2b3db6', metadata={'source': 'server/static/devel/src/monitor/data-grid-and-chart.jsx'}, page_content='\"use strict\"\\n\\nimport React, { useState, useEffect, useRef } from \"react\"\\n\\nimport { Menu } from \"../mwc/menu\"\\nimport { DataGrid } from \"./data-grid\"\\nimport { DataChart } from \"./data-chart\"\\nimport { useState2 } from \"../util\"\\n\\nexport function DataGridAndChart({ style, device_number }) {\\n    const [mode, setMode] = useState()\\n    const [duration, setDuration] = useState()\\n    // const [column, setColumn] = useState({\\n    //     field: \"epever_solar_power\",\\n    //     headerTooltip: \"Solar Power\",\\n    // }) // Plot this first\\n    const [field, setField] = useState2(\"field\", \"epever_solar_power\")\\n    const [fieldName, setFieldName] = useState()\\n    const [deviceNumbers, setDeviceNumbers] = useState([])\\n    const [time, setTime] = useState()\\n\\n    // NOTE: device state can only be either one or all, while devices state can be any combination of all devices\\n    useEffect(_ => {\\n        if (device_number > 0)\\n            setDeviceNumbers([device_number]) // One camera only\\n        else\\n            setDeviceNumbers([]) // All camera\\n    }, [device_number])')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Retrieved Document:\n",
      " \"use strict\"\n",
      "\n",
      "import React, { useState, useEffect, useRef } from \"react\"\n",
      "\n",
      "export function LivePage({\n",
      "    selectedDevice\n",
      "}) {\n",
      "    <GridContainer isGridView={selectedDevice == 0} style={{\n",
      "        flex: 1,\n",
      "        width: \"100%\",\n",
      "    }}>\n",
      "        {deviceData.map((x, i) => {\n",
      "            return (selectedDevice == 0 || selectedDevice == i + 1) && <VideoPlayer\n",
      "                key={i}\n",
      "                ref={x => video_player_refs.current[i] = x}\n",
      "                device_number={x.device_number}\n",
      "                ptz={selectedDevice == i + 1}\n",
      "                overlay={enableOverlay}\n",
      "                onClick={_ => {\n",
      "                    console.log(\"Clicked video player\", i)\n",
      "                    list_item_refs.current[i].click()\n",
      "                }}\n",
      "            ></VideoPlayer>\n",
      "        })}\n",
      "    </GridContainer>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the most relevant chunk retrieved\n",
    "print(\"Top Retrieved Document:\\n\", retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# Initialize ChatGPT with RAG (Retrieval-Augmented Generation)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import RetrievalQA\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Set up message history storage\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrap your chain with message history support\n",
    "qa_with_history = RunnableWithMessageHistory(\n",
    "    qa_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"query\",  # Changed from \"question\" to \"query\"\n",
    "    history_messages_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll explain the React code step by step, and then explain how it connects with the Python Tornado Websocket.\n",
      "\n",
      "**React Code**\n",
      "\n",
      "```javascript\n",
      "// WebSocketVideoPlayer component\n",
      "export function WebSocketVideoPlayer({\n",
      "  ws_ref, // optional\n",
      "  url,\n",
      "  videoPath, // optional\n",
      "  onFirstFrame,\n",
      "  onFrame,\n",
      "  showOverlay,\n",
      "  verbose,\n",
      "  extraText,\n",
      "  style,\n",
      "  ...props\n",
      "}) {\n",
      "  // State variables\n",
      "  const [videoState, setVideoState] = useState(DISCONNECTED);\n",
      "  const [urlAndPayload, setUrlAndPayload] = useState({});\n",
      "  const [decoderKey, setDecoderKey] = useState();\n",
      "\n",
      "  // References\n",
      "  const fg_fast_ref = useRef();\n",
      "  const fg_slow_ref = useRef();\n",
      "  const bg_ref = useRef();\n",
      "  const decoder_ref = useRef();\n",
      "  ws_ref = ws_ref || useRef();\n",
      "\n",
      "  // Effect hook to initialize WebSocket connection when URL changes\n",
      "  useEffect(() => {\n",
      "    if (!url) return; // No WebSocket connection if URL is empty\n",
      "    // Create a unique key to prevent identical payloads from interfering with each other\n",
      "    const x = { url, key: +new Date() };\n",
      "    if (videoPath) x.payload = { path: videoPath, height: 720, bitrate: 2048 };\n",
      "    setUrlAndPayload(x);\n",
      "    setDecoderKey(+new Date());\n",
      "    setVideoState(CONNECTING);\n",
      "  }, [url, videoPath]);\n",
      "\n",
      "  // Render the component based on its state\n",
      "  // ...\n",
      "}\n",
      "```\n",
      "\n",
      "Here's a step-by-step explanation:\n",
      "\n",
      "1. The `WebSocketVideoPlayer` component takes several props, including `ws_ref` (an optional reference to a WebSocket instance), `url`, and `videoPath`.\n",
      "2. The component defines four state variables using `useState`:\n",
      "\t* `videoState`: the current state of the WebSocket connection (e.g., \"Disconnected\", \"Connecting\", etc.)\n",
      "\t* `urlAndPayload`: the URL and payload data for the WebSocket connection\n",
      "\t* `decoderKey`: a unique key for the decoder\n",
      "\t* `ws_ref`: a reference to the WebSocket instance (optional)\n",
      "3. The component defines several references using `useRef`:\n",
      "\t* `fg_fast_ref`, `fg_slow_ref`, and `bg_ref`: references to canvas elements\n",
      "\t* `decoder_ref`: a reference to the decoder instance\n",
      "\t* `ws_ref`: a reference to the WebSocket instance (optional)\n",
      "4. The `useEffect` hook is used to initialize the WebSocket connection when the `url` or `videoPath` props change. If the `url` is empty, the effect hook returns without doing anything.\n",
      "5. Inside the effect hook:\n",
      "\t* A unique key is created by combining the `url` and a timestamp (`+new Date()`).\n",
      "\t* If `videoPath` is provided, the payload data is created with the video path, height, and bitrate.\n",
      "\t* The `urlAndPayload` and `decoderKey` state variables are updated with the new data.\n",
      "\t* The `videoState` state variable is updated to \"Connecting\".\n",
      "\n",
      "**Connecting to Python Tornado Websocket**\n",
      "\n",
      "The React `WebSocketVideoPlayer` component is connected to the Python Tornado Websocket using the `WebSocket2` component, which is a React hook that wraps the Tornado Websocket API.\n",
      "\n",
      "```javascript\n",
      "// WebSocket2 hook\n",
      "import { WebSocket2 } from \"./websocket\";\n",
      "\n",
      "function getDeviceRoot(device_number) {\n",
      "  const subdir = location.pathname.split(\"/\")[1];\n",
      "  return `${location.host}/${subdir}/${device_number}`;\n",
      "}\n",
      "\n",
      "export function Player({ device_number, style }) {\n",
      "  const ws_url = `wss://${getDeviceRoot(device_number)}/recorder/api/ws`;\n",
      "  const ws_ref = useRef();\n",
      "\n",
      "  useEffect(() => {\n",
      "    const { urlAndPayload } = ws_url;\n",
      "    if (!urlAndPayload) return; // No WebSocket connection if URL is empty\n",
      "    const ws = ws_ref.current = new WebSocket(urlAndPayload);\n",
      "    ws.binaryType = \"arraybuffer\";\n",
      "    // ...\n",
      "  }, [ws_url]);\n",
      "\n",
      "  return (\n",
      "    <WebSocket2\n",
      "      ref={ws_ref}\n",
      "      urlAndPayload={ws_url}\n",
      "      onMessage={(data) => {\n",
      "        // Handle WebSocket message data\n",
      "      }}\n",
      "    />\n",
      "  );\n",
      "}\n",
      "```\n",
      "\n",
      "Here's what's happening:\n",
      "\n",
      "1. The `Player` component takes a `device_number` prop, which is used to construct the WebSocket URL.\n",
      "2. The `getDeviceRoot` function returns the WebSocket URL by concatenating the device root URL with the `device_number`.\n",
      "3. The `WebSocket2` hook is used to create a WebSocket connection with the `ws_url`.\n",
      "4. The `useEffect` hook is used to initialize the WebSocket connection when the `ws_url` changes.\n",
      "5. Inside the effect hook:\n",
      "\t* A new WebSocket instance is created with the `ws_url`.\n",
      "\t* The `binaryType` property is set to \"arraybuffer\" to enable binary message reception.\n",
      "6. The `WebSocket2` hook is used to render the WebSocket connection and handle messages from the server.\n",
      "\n",
      "**Python Tornado Websocket**\n",
      "\n",
      "The Python Tornado Websocket code is used to create a WebSocket server that accepts connections from the React client. Here's a simplified example:\n",
      "\n",
      "```python\n",
      "from tornado.websocket import WebSocketHandler\n",
      "from tornado.web import Application, RequestHandler\n",
      "from tornado.ioloop import IOLoop\n",
      "\n",
      "class StreamHandler(WebSocketHandler):\n",
      "    def initialize(self, ioloop, clients):\n",
      "        self.ioloop = ioloop\n",
      "        self.clients = clients\n",
      "\n",
      "    def open(self):\n",
      "        self.clients.add(self)\n",
      "        print(\"WebSocket connection established\")\n",
      "\n",
      "    def on_message(self, message):\n",
      "        print(\"Received message:\", message)\n",
      "        # Handle message from client\n",
      "\n",
      "    def on_close(self):\n",
      "        self.clients.remove(self)\n",
      "        print(\"WebSocket connection closed\")\n",
      "```\n",
      "\n",
      "Here's what's happening:\n",
      "\n",
      "1. The `StreamHandler` class inherits from `WebSocketHandler` and defines the WebSocket connection lifecycle methods:\n",
      "\t* `open`: called when a client connects to the WebSocket server\n",
      "\t* `on_message`: called when a client sends a message to the WebSocket server\n",
      "\t* `on_close`: called when a client disconnects from the WebSocket server\n",
      "2. The `initialize` method is called when the WebSocket handler is created, and it takes a `clients` list as an argument.\n",
      "3. The `clients` list is used to keep track of connected clients and send messages to them.\n",
      "\n",
      "Note that this is a highly simplified example and you may need to add additional features such as authentication, authorization, and error handling to your WebSocket server.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "session_id = \"user123\"\n",
    "\n",
    "# First question - notice we use \"query\" as the key\n",
    "response = qa_with_history.invoke(\n",
    "    {\"query\": \"\"\"explain react code. how its connected with python tornado websocket \n",
    "                explain briefly each and every code by writing it step by step\"\"\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the React base code as per the provided context:\n",
      "\n",
      "```javascript\n",
      "\"use strict\"\n",
      "\n",
      "import { createRoot } from \"react-dom/client\"\n",
      "import React, { useState, useEffect, useRef } from \"react\"\n",
      "\n",
      "import { Drawer } from \"./mwc/drawer\"\n",
      "import { List, ListItem, Divider } from \"./mwc/list\"\n",
      "import { Icon, IconButton } from \"./mwc/icon\"\n",
      "import { TabBar, Tab } from \"./mwc/tab-bar\"\n",
      "\n",
      "import { LeftAndRightLogo, WhiteLogo } from \"./logo\"\n",
      "import { useState2 } from \"./util\"\n",
      "import { DeviceList } from \"./device-list\"\n",
      "import { LivePage } from \"./live/live-page\"\n",
      "import { RecorderPage } from \"./recorder/recorder-page\"\n",
      "\n",
      "import { getTXRX } from \"./recorder/websocket\"\n",
      "\n",
      "import { DataGridAndChart } from \"./monitor/data-grid-and-chart\"\n",
      "\n",
      "function App() {\n",
      "    const [drawerOpen, setDrawerOpen] = useState(false)\n",
      "    const [selectAllDisabled, setSelectAllDisabled] = useState()\n",
      "    const [compactLayout, setCompactLayout] = useState(false)\n",
      "\n",
      "    // URL hash states\n",
      "    const [tabValue, setTabValue] = useState2(\"tab\", \"Live\")\n",
      "    const [selectedDevice, setSelectedDevice] = useState2(\"device\", 0)\n",
      "\n",
      "    const num_device = 6\n",
      "\n",
      "    useEffect(_ => {\n",
      "        if (tabValue == \"Recorder\")\n",
      "            setSelectAllDisabled(true)\n",
      "        else\n",
      "            setSelectAllDisabled(false)\n",
      "    }, [tabValue])\n",
      "\n",
      "    useEffect(_ => {\n",
      "        setDrawerOpen(false)\n",
      "    }, [selectedDevice])\n",
      "\n",
      "    function onResize() {\n",
      "        setCompactLayout(window.innerWidth < 800)\n",
      "    }\n",
      "\n",
      "    useEffect(_ => {\n",
      "        // setInterval(_ => console.log(getTXRX()), 1000)\n",
      "        addEventListener(\"resize\", _ => onResize())\n",
      "        onResize()\n",
      "    }, [])\n",
      "}\n",
      "```\n",
      "\n",
      "```javascript\n",
      "\"use strict\"\n",
      "\n",
      "import React, { useState, useEffect, useRef } from \"react\"\n",
      "import \"@material/mwc-button\"\n",
      "\n",
      "import { Dialog } from \"../mwc/dialog\"\n",
      "import { Snackbar } from \"../mwc/snackbar\"\n",
      "import { toSizeString } from \"../util\"\n",
      "import { Button } from \"./playback-control\"\n",
      "\n",
      "export function download(url, path) {\n",
      "    const a = document.createElement(\"a\")\n",
      "    a.href = url\n",
      "    a.download = path || url.split(\"/\").slice(-1)[0]\n",
      "    a.click()\n",
      "}\n",
      "\n",
      "const cellular_warning = <div style={{\n",
      "    // fontWeight: \"bold\", color: \"#c00\"\n",
      "}}>{\"Cellular charges may apply\"}</div>\n",
      "```\n",
      "\n",
      "```javascript\n",
      "\"use strict\"\n",
      "\n",
      "import React, { useState, useEffect, useRef } from \"react\"\n",
      "\n",
      "import { toSizeString } from \"../util\"\n",
      "\n",
      "export function Thumbnail({ size, date, img_src, isLive, data, style, ...props }) {\n",
      "    // console.log(x)\n",
      "    const ref = useRef()\n",
      "    let size_string = toSizeString(size)\n",
      "    size_string = `${size_string}B`\n",
      "    const date_string = date.toLocaleString(\"en-US\", {\n",
      "        month: \"short\", day: \"numeric\",\n",
      "        hour12: false, hour: \"numeric\", minute: \"numeric\",\n",
      "    })\n",
      "    const overlay_styles = {\n",
      "        position: \"absolute\",\n",
      "        background: \"#0008\",\n",
      "        padding: \"1 6\",\n",
      "        borderRadius: \"8px\",\n",
      "    }\n",
      "    return <div ref={ref} {...props} style={{\n",
      "        position: \"relative\",\n",
      "        cursor: \"pointer\",\n",
      "        fontFamily: \"Roboto\",\n",
      "        fontSize: \"small\",\n",
      "        color: \"white\",\n",
      "        height: \"100%\",\n",
      "        aspectRatio: \"16/9\",\n",
      "        boxSizing: \"border-box\",\n",
      "        ...style,\n",
      "    }}\n",
      "    >\n",
      "        <img\n",
      "            src={img_src}\n",
      "            loading=\"lazy\"\n",
      "            style={{ width: \"100%\", height: \"100%\", background: \"#888\" }}\n",
      "        ></img>\n",
      "        <div style={{ ...overlay_styles, bottom: 2, right: 2 }}>{size_string + (isLive ? \"+\" : \"\")}</div>\n",
      "        <div style={{ ...overlay_styles, top: 2, left: 2 }}>{date_string}</div>\n",
      "    </div >\n",
      "}\n",
      "```\n",
      "\n",
      "```javascript\n",
      "\"use strict\"\n",
      "\n",
      "import React, { useState, useEffect, useRef } from \"react\"\n",
      "\n",
      "import { ListItem } from \"./mwc/list\"\n",
      "import { Icon, CroppedIcon, BatteryIcon } from \"./mwc/icon\"\n",
      "import { toDurationString, getDeviceName } from \"./util\"\n",
      "import { queryInflux } from \"./influx\"\n",
      "\n",
      "import \"./skeleton-loading.css\"\n",
      "\n",
      "export function DeviceList({ selected, numDevice, setSelected, interval = 300 }) {\n",
      "    const [deviceData, setDeviceData] = useState([])\n",
      "\n",
      "    async function pullData() {\n",
      "        // NOTE: SELECT uptime is dummy, need to SELECT something reliable to get list of devices\n",
      "        let data = await queryInflux(`\n",
      "        SELECT LAST(uptime) AS uptime\n",
      "        FROM cag_otter\n",
      "            WHERE TIME > NOW() - 30d\n",
      "        GROUP BY device, TIME(1h)\n",
      "        `)\n",
      "        // Prefill with placeholders for rendering\n",
      "        setDeviceData(Array(numDevice).fill().map(_ => []))\n",
      "\n",
      "        const device_numbers = Array(numDevice).fill().map((_, i) => i + 1)\n",
      "        const data_by_device = Object.fromEntries(await Promise.all(device_numbers.map(async n => {\n",
      "            const device = `otterbox${n}`\n",
      "            const device_name = await getDeviceName(n)\n",
      "            return [device, { device_name: device_name, device_number: n }]\n",
      "        })))\n",
      "\n",
      "        const now = new Date()\n",
      "        const midnight = new Date(now)\n",
      "        midnight.setHours(0, 0, 0, 0)\n",
      "        if (now.getHours() == 0) // Allow 1 hour of data collection\n",
      "            midnight.setDate(midnight.getDate() - 1)\n",
      "        data = await queryInflux(`\n",
      "            SELECT\n",
      "            uptime as uptime,\n",
      "            epever_battery_state_of_charge AS soc,\n",
      "            epever_solar_power AS solar_power,\n",
      "            epever_total_generated_energy AS generated\n",
      "            FROM cag_otter WHERE TIME > '${midnight.toISOString()}'\n",
      "            GROUP BY device\n",
      "        `)\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "Let me know if you want me to fetch anything else.\n"
     ]
    }
   ],
   "source": [
    "# First question\n",
    "# First question - notice we use \"query\" as the key\n",
    "response = qa_with_history.invoke(\n",
    "    {\"query\": \"\"\"fetch all React base code and write it down\"\"\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the code you provided, I don't see any information about the file structure of the codebase. However, I can try to infer the file structure based on the code.\n",
      "\n",
      "Here's a possible file structure for the codebase:\n",
      "\n",
      "```\n",
      ".\n",
      "inert_subroot.py\n",
      "inert_node.py\n",
      "pipeline_handler.py\n",
      "gstreamer_utils.py\n",
      "common.py\n",
      "utils.py\n",
      "main.py\n",
      "requirements.txt\n",
      "glob.py (imported, likely a custom implementation)\n",
      "disk_usage.py (imported, likely a custom implementation)\n",
      "IOLoop.py (imported, likely a custom implementation)\n",
      "Gst.py (imported, likely a custom implementation)\n",
      "influx_query.py (imported, likely a custom implementation)\n",
      "config.py (possible, not shown in the code)\n",
      "EXTERNAL_ROOT (path, likely a configuration)\n",
      "INTERNAL_ROOT (path, likely a configuration)\n",
      "```\n",
      "\n",
      "To fetch the actual tree of files in the codebase, you can use the `os` module in Python:\n",
      "\n",
      "```python\n",
      "import os\n",
      "\n",
      "def get_file_tree():\n",
      "    for root, dirs, files in os.walk(\".\"):\n",
      "        for dir in dirs:\n",
      "            print(f\"  {dir}\")\n",
      "        for file in files:\n",
      "            print(f\"    {file}\")\n",
      "        print(f\"  {os.path.relpath(root)}\")\n",
      "        print()\n",
      "\n",
      "get_file_tree()\n",
      "```\n",
      "\n",
      "This will print the file tree of the current directory and its subdirectories.\n",
      "\n",
      "If you want to include the file paths in the output, you can modify the function like this:\n",
      "\n",
      "```python\n",
      "import os\n",
      "\n",
      "def get_file_tree():\n",
      "    for root, dirs, files in os.walk(\".\"):\n",
      "        print(f\"  {os.path.relpath(root)}\")\n",
      "        for dir in dirs:\n",
      "            print(f\"    {dir}\")\n",
      "        for file in files:\n",
      "            print(f\"      {os.path.join(root, file)}\")\n",
      "        print()\n",
      "\n",
      "get_file_tree()\n",
      "```\n",
      "\n",
      "Note: This will print the file tree to the console. If you want to store the output in a file, you can modify the function to write the output to a file instead of printing it to the console.\n"
     ]
    }
   ],
   "source": [
    "response = qa_with_history.invoke(\n",
    "    {\"query\": \"\"\"fetch tree of files in codebase provided\"\"\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question and get an answer\n",
    "query = \"explain react code. how its connected with python tornado wesocket\"\n",
    "response = qa_chain.run(query)\n",
    "\n",
    "# Print the generated response\n",
    "print(\"\\nGenerated Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question and get an answer\n",
    "query = \"\"\"explain react code. how its connected with python tornado wesocket\n",
    "explain brifly each and every code\n",
    "\"\"\"\n",
    "response = qa_chain.run(query)\n",
    "\n",
    "# Print the generated response\n",
    "print(\"\\nGenerated Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for our RAG application and teaching agent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "import glob\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "import time  # For timing stages\n",
    "\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Step 1: Setup Environment and LLM\n",
    "# This is like setting up your classroom with the right tools\n",
    "def setup_environment():\n",
    "    load_dotenv()\n",
    "    if not os.getenv(\"GROQ_API_KEY\"):\n",
    "        raise ValueError(\"Please set GROQ_API_KEY in your .env file!\")\n",
    "    llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    print(\"Environment setup complete. Your AI teacher is ready!\")\n",
    "    return llm\n",
    "\n",
    "llm = setup_environment()\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import re\n",
    "\n",
    "def generate_tree_structure(directory):\n",
    "    \"\"\"Generate a textual representation of the directory tree.\"\"\"\n",
    "    tree = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        level = root.replace(directory, '').count(os.sep)\n",
    "        indent = '  ' * level\n",
    "        tree.append(f\"{indent}{os.path.basename(root)}/\")\n",
    "        for f in files:\n",
    "            tree.append(f\"{indent}  {f}\")\n",
    "    return \"\\n\".join(tree)\n",
    "\n",
    "def infer_code_flow(files, directory):\n",
    "    \"\"\"Basic inference of code flow by looking at imports/requires.\"\"\"\n",
    "    flow = []\n",
    "    import_patterns = {\n",
    "        'py': r\"import\\s+[\\w.]+\\s*(?:as\\s+\\w+)?|from\\s+[\\w.]+\\s+import\\s+[\\w.*]+\",\n",
    "        'js': r\"import\\s+.*?\\s+from\\s+['\\\"].*?['\\\"]|require\\(['\\\"].*?['\\\"]\\)\",\n",
    "        'jsx': r\"import\\s+.*?\\s+from\\s+['\\\"].*?['\\\"]|require\\(['\\\"].*?['\\\"]\\)\"\n",
    "    }\n",
    "    \n",
    "    for file_path in files:\n",
    "        ext = file_path.rsplit('.', 1)[-1] if '.' in file_path else ''\n",
    "        if ext in import_patterns:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                imports = re.findall(import_patterns[ext], content)\n",
    "                if imports:\n",
    "                    rel_path = os.path.relpath(file_path, directory)\n",
    "                    flow.append(f\"{rel_path} depends on:\")\n",
    "                    for imp in imports:\n",
    "                        flow.append(f\"  - {imp.strip()}\")\n",
    "            except Exception as e:\n",
    "                flow.append(f\"Error analyzing {file_path}: {e}\")\n",
    "    return \"\\n\".join(flow) if flow else \"No detectable dependencies found.\"\n",
    "\n",
    "def load_documents(directory=\"code_folder\"):\n",
    "    \"\"\"Load code files, tree, and flow from the directory.\"\"\"\n",
    "    # Verify directory exists\n",
    "    abs_dir = os.path.abspath(directory)\n",
    "    if not os.path.isdir(abs_dir):\n",
    "        print(f\"Error: Directory '{abs_dir}' does not exist!\")\n",
    "        return []\n",
    "    print(f\"Scanning directory: {abs_dir}\")\n",
    "\n",
    "    # Define supported extensions\n",
    "    extensions = (\"py\", \"js\", \"jsx\", \"ts\", \"java\", \"c\", \"cpp\", \"cs\", \"go\", \"rs\", \n",
    "                  \"php\", \"rb\", \"sh\", \"txt\", \"md\", \"html\", \"css\", \"yaml\", \"yml\", \"conf\")\n",
    "    glob_pattern = \"**/*.{\" + \",\".join(extensions) + \"}\"\n",
    "    print(f\"Using glob pattern: {glob_pattern}\")\n",
    "\n",
    "    # Find all matching files\n",
    "    matching_files = []\n",
    "    for ext in extensions:\n",
    "        matching_files.extend(glob.glob(os.path.join(directory, f\"**/*.{ext}\"), recursive=True))\n",
    "    print(f\"Found {len(matching_files)} files:\")\n",
    "    for file in matching_files[:5]:\n",
    "        print(f\"  {file}\")\n",
    "    if len(matching_files) > 5:\n",
    "        print(f\"  ...and {len(matching_files) - 5} more\")\n",
    "\n",
    "    # Load documents\n",
    "    documents = []\n",
    "\n",
    "\n",
    "    # Add tree structure\n",
    "    tree_content = generate_tree_structure(directory)\n",
    "    documents.append(Document(page_content=tree_content, metadata={\"source\": \"files tree\"}))\n",
    "\n",
    "    # Add code flow\n",
    "    flow_content = infer_code_flow(matching_files, directory)\n",
    "    documents.append(Document(page_content=flow_content, metadata={\"source\": \"code flow\"}))\n",
    "\n",
    "\n",
    "    for file_path in matching_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            doc = Document(page_content=content, metadata={\"source\": os.path.relpath(file_path, directory)})\n",
    "            documents.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {file_path}: {e}\")\n",
    "\n",
    "\n",
    "    # Split into chunks with optimized size\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Loaded {len(documents)} files, split into {len(split_docs)} chunks\")\n",
    "    return split_docs\n",
    "\n",
    "\n",
    "\n",
    "def create_vector_store(docs, persist_dir=\"./chroma_db\"):\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"mxbai-embed-large\",\n",
    "    )\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "    print(f\"Vector store created at {persist_dir}\")\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "def load_chroma_retriever(persist_dir: str = \"./chroma_db\"):\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"mxbai-embed-large\",\n",
    "    )\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=persist_dir,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    return vector_store.as_retriever()\n",
    "\n",
    "\n",
    "code_directory=\"otter-detection\"\n",
    "persist_dir=\"./chroma_db\"\n",
    "if not os.path.exists(persist_dir):\n",
    "    docs = load_documents(code_directory)\n",
    "    if docs:\n",
    "        create_vector_store(docs, persist_dir)\n",
    "    else:\n",
    "        print(\"No code files found!\")\n",
    "# Initialize the retriever tool\n",
    "retriever = load_chroma_retriever()\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"codebase_retriever\",\n",
    "    \"Search for information about the codebase related componets codes\"\n",
    ")\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "# Initialize ChatGPT with RAG (Retrieval-Augmented Generation)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "\n",
    "# from langchain.chains import RetrievalQA\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Set up message history storage\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrap your chain with message history support\n",
    "qa_with_history = RunnableWithMessageHistory(\n",
    "    qa_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"query\",  # Changed from \"question\" to \"query\"\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "session_id = \"user123\"\n",
    "\n",
    "# First question - notice we use \"query\" as the key\n",
    "response = qa_with_history.invoke(\n",
    "    {\"query\": \"\"\"explain react code. how its connected with python tornado websocket \n",
    "                explain briefly each and every code by writing it step by step\"\"\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
